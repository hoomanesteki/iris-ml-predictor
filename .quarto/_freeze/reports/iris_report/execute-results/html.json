{
  "hash": "e9f6ec27a675a3e9ad2f9dfcbd13d109",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Flower Species Classification Based on Iris Dataset\"\nauthor: \"Suryash Chakravarty, Hooman Esteki, Bright Arafat Bello\"\ndate: \"2025/12/12\"\njupyter: python3\nformat: \n  html:\n    toc: true\n    toc-depth: 3\n    embed-resources: true\n  typst:\n    toc: true\n    toc-depth: 3\nbibliography: references.bib\nexecute:\n  echo: false\n  warning: false\n  message: false\neditor: source\n---\n\nGitHub URL: [https://github.com/hoomanesteki/iris-ml-predictor](https://github.com/hoomanesteki/iris-ml-predictor)\n\n\n\n## Summary\n\nThe present endeavor constructs a model that classifies iris flower species through the classic Iris dataset @iris_53. It was a four-dimensional feature set, which consisted of sepal length, sepal width, petal length, and petal width that was employed to get a Decision Tree Classifier. The model's performance was determined using a separate test set, and accuracy levels of 93.33% were observed, which is quite a strong one.\n\nThe Iris dataset is often utilized for teaching machine learning because of its uncomplicated nature and distinct class structure. Nevertheless, the limitations of the small dataset containing 150 samples and the overlap of features between *versicolor* and *virginica* make it harder to generalize. Our model, regardless of these restrictions, still manages to exhibit high classification performance and serve as a robust baseline for multilabel prediction tasks.\n\nNB: Some of the code for our analysis was adapted from courses at the Masters Of Data Science program at UBC, particularly;\n1. DSCI 571: Supervised Learning I; @dsci571_materials\n2. DSCI 522: Data Science Workflows; @dsci522_milestone\n\n## Introduction\n\nThe 150 samples in the Iris dataset are determined by four numerical characteristics which together give the dimensions of the iris flowers. The target variable consists of three species: *Iris setosa*, *Iris versicolor*, and *Iris virginica*. In the main, the analysis has the aim of identifying if the machine learning model—in this case, a Decision Tree Classifier—can make correct predictions of species identity relying only on these measurements.\n\nThe machine learning process outlined in this report is an entire cycle consisting of data exploration, cleaning, and transformation, modeling and finally, evaluation. Access to the full code and scripts that were used for the analysis is provided through the GitHub repository: https://github.com/hoomanesteki/iris-ml-predictor.\n\n## Methods\n\n### Data Source and Preprocessing\n\nThe collection of data was obtained from the UCI Machine Learning Repository @iris_53. There are no missing values in the dataset, and 50 samples represent each of the three classes. The class labels were converted into numbers (0 = setosa, 1 = versicolor, 2 = virginica). A train-test split @scikit_learn, was done to maintain the separation of training and testing data. This will help evaluate the model's performance on previously unseen data.\n\n### Exploratory Data Analysis\n\nSeaborn @Waskom2021 was used to create exploratory visualizations to know the distributions and separability of features:\n\n- Pairplot to see class clustering @fig-pplot\n\n![Pairplot of Features vs Target](results/figures/pairplot.png){#fig-pplot width=70%}\n\n- Correlation heatmap to find correlations among quantitative features @fig-corr\n\n![Heatmap of Correlation (1.0 = High +ve Correlation, 0 = No Correlation)](results/figures/corr.png){#fig-corr width=70%}\n\n- Distribution plot indicating differences in petal length among species @fig-hist\n\n![Histogram of Classes vs Petal Width](results/figures/histplot.png){#fig-hist width=70%}\n\nThe visualizations indicate that *setosa* is completely isolated from the remaining two species whereas *versicolor* and *virginica* have slightly overlapping areas.\n\n### Model Building\n\nA DummyClassifier (actually a classifier with no intelligence at all) was employed as a reference point for the performance comparison. \n\n\n\n![Confusion matrix](results/figures/dummy_confusion_matrix.png){#fig-dum_conf width=70%}\n\nWe observed nearly 27.03% correct predictions for the three equally balanced classes.\n\nSubsequently, a Decision Tree Classifier was fitted to capture the nonlinear patterns through the four input features.\n\n::: {#tbl-metrics .cell tbl-cap='Decision Tree Classifier Performance Metrics' execution_count=3}\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<style type=\"text/css\">\n#T_aa5f4 th {\n  background-color: #f5f5f5;\n}\n</style>\n<table id=\"T_aa5f4\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_aa5f4_level0_col0\" class=\"col_heading level0 col0\" >accuracy</th>\n      <th id=\"T_aa5f4_level0_col1\" class=\"col_heading level0 col1\" >precision_weighted</th>\n      <th id=\"T_aa5f4_level0_col2\" class=\"col_heading level0 col2\" >recall_weighted</th>\n      <th id=\"T_aa5f4_level0_col3\" class=\"col_heading level0 col3\" >f1_weighted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_aa5f4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n      <td id=\"T_aa5f4_row0_col0\" class=\"data row0 col0\" >0.933333</td>\n      <td id=\"T_aa5f4_row0_col1\" class=\"data row0 col1\" >0.950000</td>\n      <td id=\"T_aa5f4_row0_col2\" class=\"data row0 col2\" >0.933333</td>\n      <td id=\"T_aa5f4_row0_col3\" class=\"data row0 col3\" >0.934762</td>\n    </tr>\n  </tbody>\n</table>\n```\n:::\n:::\n\n\n## Results & Discussion\n\nThe Decision Tree classifier produced a test accuracy of 93.33%, which is a considerable improvement over the baseline dummy model. This is a strong indication that the model was able to recognize and utilize the underlying patterns in the data.\n\n![Confusion matrix](results/figures/confusion_matrix.png){#fig-conf width=70%}\n\nThe confusion matrix (@fig-conf) highlights:\n\n- The classification of *setosa* is perfect.\n- There are some misclassifications between *versicolor* and *virginica*, which is in line with the feature distributions that overlap.\n\n### Interpretation\n\nSetosa is distinguished without doubt by its distinct petal features. The mentioned mix up between *versicolor* and *virginica* indicates:\n\n- Feature intersection hampers the linear or rule based separation\n- A more complex or regularized decision tree might be beneficial\n- More sophisticated models (such as Random Forest, SVM) might have better performance\n\n### Future Work\n\nIn order to elevate the model’s power and generalization:\n\n- Tune the hyperparameters (maximum depth, minimum samples split)\n- Try out other classifiers and evaluate them\n- Apply k-fold cross-validation to obtain a stability of results\n- Look into the importance of features and concentrates on misclassified samples\n- Consider the use of ensemble models as a means of improving robustness\n\n",
    "supporting": [
      "iris_report_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}